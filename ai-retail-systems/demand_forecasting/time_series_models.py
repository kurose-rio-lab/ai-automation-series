"""
æ™‚ç³»åˆ—åˆ†æã«ã‚ˆã‚‹éœ€è¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
ARIMAã€æŒ‡æ•°å¹³æ»‘æ³•ã€å­£ç¯€åˆ†è§£ãªã©ã®æ™‚ç³»åˆ—æ‰‹æ³•ã‚’å®Ÿè£…
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.metrics import mean_absolute_error, mean_squared_error
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class TimeSeriesForecaster:
    def __init__(self):
        """æ™‚ç³»åˆ—äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–"""
        self.models = {}
        self.forecast_results = {}
        
    def load_and_prepare_data(self, file_path: str, product_id: str = None):
        """ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†"""
        try:
            df = pd.read_csv(file_path)
            df['date'] = pd.to_datetime(df['date'])
            
            if product_id:
                df = df[df['product_id'] == product_id]
            
            # æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
            df = df.set_index('date').resample('D')['quantity'].sum().fillna(0)
            
            print(f"ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {len(df)}æ—¥åˆ†")
            return df
            
        except Exception as e:
            print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def check_stationarity(self, ts_data, title="Time Series"):
        """å®šå¸¸æ€§ã®ç¢ºèªï¼ˆADFæ¤œå®šï¼‰"""
        result = adfuller(ts_data.dropna())
        
        print(f"\n=== {title} ã®å®šå¸¸æ€§æ¤œå®šçµæœ ===")
        print(f'ADFçµ±è¨ˆé‡: {result[0]:.6f}')
        print(f'på€¤: {result[1]:.6f}')
        print(f'è‡¨ç•Œå€¤:')
        for key, value in result[4].items():
            print(f'\t{key}: {value:.3f}')
        
        if result[1] <= 0.05:
            print("çµæœ: å®šå¸¸ã§ã‚ã‚‹ï¼ˆp < 0.05ï¼‰")
            return True
        else:
            print("çµæœ: éå®šå¸¸ã§ã‚ã‚‹ï¼ˆp >= 0.05ï¼‰")
            return False
    
    def make_stationary(self, ts_data):
        """éå®šå¸¸ãƒ‡ãƒ¼ã‚¿ã®å®šå¸¸åŒ–"""
        # 1æ¬¡å·®åˆ†
        diff_data = ts_data.diff().dropna()
        
        if self.check_stationarity(diff_data, "1æ¬¡å·®åˆ†"):
            return diff_data, 1
        
        # 2æ¬¡å·®åˆ†
        diff2_data = diff_data.diff().dropna()
        if self.check_stationarity(diff2_data, "2æ¬¡å·®åˆ†"):
            return diff2_data, 2
        
        # å¯¾æ•°å¤‰æ› + å·®åˆ†
        log_data = np.log1p(ts_data)
        log_diff_data = log_data.diff().dropna()
        
        if self.check_stationarity(log_diff_data, "å¯¾æ•°å·®åˆ†"):
            return log_diff_data, "log_diff"
        
        return diff_data, 1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1æ¬¡å·®åˆ†
    
    def seasonal_decomposition(self, ts_data, period=7):
        """å­£ç¯€åˆ†è§£ã®å®Ÿè¡Œ"""
        try:
            if len(ts_data) < 2 * period:
                print("ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚å­£ç¯€åˆ†è§£ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                return None
            
            decomposition = seasonal_decompose(
                ts_data, 
                model='additive', 
                period=period
            )
            
            # å¯è¦–åŒ–
            fig, axes = plt.subplots(4, 1, figsize=(15, 12))
            
            decomposition.observed.plot(ax=axes[0], title='Original')
            decomposition.trend.plot(ax=axes[1], title='Trend')
            decomposition.seasonal.plot(ax=axes[2], title='Seasonal')
            decomposition.resid.plot(ax=axes[3], title='Residual')
            
            plt.tight_layout()
            
            # ä¿å­˜
            output_dir = Path("results/forecasting")
            output_dir.mkdir(parents=True, exist_ok=True)
            plt.savefig(output_dir / "seasonal_decomposition.png", dpi=300, bbox_inches='tight')
            
            return decomposition
            
        except Exception as e:
            print(f"å­£ç¯€åˆ†è§£ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def auto_arima_selection(self, ts_data, max_p=5, max_d=2, max_q=5):
        """ARIMA ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è‡ªå‹•é¸æŠï¼ˆAICåŸºæº–ï¼‰"""
        best_aic = float('inf')
        best_params = None
        best_model = None
        
        print("ARIMA ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ä¸­...")
        
        for p in range(max_p + 1):
            for d in range(max_d + 1):
                for q in range(max_q + 1):
                    try:
                        model = ARIMA(ts_data, order=(p, d, q))
                        fitted_model = model.fit()
                        
                        if fitted_model.aic < best_aic:
                            best_aic = fitted_model.aic
                            best_params = (p, d, q)
                            best_model = fitted_model
                            
                    except Exception:
                        continue
        
        print(f"æœ€é©ARIMA ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {best_params}, AIC: {best_aic:.2f}")
        return best_model, best_params
    
    def fit_arima_model(self, ts_data, order=None):
        """ARIMA ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’"""
        try:
            if order is None:
                model, params = self.auto_arima_selection(ts_data)
            else:
                arima_model = ARIMA(ts_data, order=order)
                model = arima_model.fit()
                params = order
            
            self.models['arima'] = {
                'model': model,
                'params': params,
                'aic': model.aic
            }
            
            print(f"ARIMA{params} ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº† (AIC: {model.aic:.2f})")
            return model
            
        except Exception as e:
            print(f"ARIMA ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def fit_exponential_smoothing(self, ts_data, seasonal_periods=7):
        """æŒ‡æ•°å¹³æ»‘æ³•ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’"""
        try:
            # ã‚·ãƒ³ãƒ—ãƒ«æŒ‡æ•°å¹³æ»‘æ³•
            simple_model = ExponentialSmoothing(ts_data, trend=None, seasonal=None)
            simple_fit = simple_model.fit()
            
            # Holtæ³•ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰è€ƒæ…®ï¼‰
            holt_model = ExponentialSmoothing(ts_data, trend='add', seasonal=None)
            holt_fit = holt_model.fit()
            
            # Holt-Wintersæ³•ï¼ˆå­£ç¯€æ€§è€ƒæ…®ï¼‰
            if len(ts_data) >= 2 * seasonal_periods:
                hw_model = ExponentialSmoothing(
                    ts_data, 
                    trend='add', 
                    seasonal='add', 
                    seasonal_periods=seasonal_periods
                )
                hw_fit = hw_model.fit()
            else:
                hw_fit = holt_fit  # ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å ´åˆã¯Holtæ³•ã‚’ä½¿ç”¨
            
            # AIC ã§æœ€é©ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
            models_to_compare = {
                'simple': simple_fit,
                'holt': holt_fit,
                'holt_winters': hw_fit
            }
            
            best_model = min(models_to_compare.items(), key=lambda x: x[1].aic)
            
            self.models['exponential_smoothing'] = {
                'model': best_model[1],
                'type': best_model[0],
                'aic': best_model[1].aic
            }
            
            print(f"æŒ‡æ•°å¹³æ»‘æ³• ({best_model[0]}) ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº† (AIC: {best_model[1].aic:.2f})")
            return best_model[1]
            
        except Exception as e:
            print(f"æŒ‡æ•°å¹³æ»‘æ³•ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def generate_forecasts(self, steps=30):
        """äºˆæ¸¬ã®å®Ÿè¡Œ"""
        forecasts = {}
        
        for model_name, model_info in self.models.items():
            try:
                model = model_info['model']
                
                if model_name == 'arima':
                    forecast = model.forecast(steps=steps)
                    conf_int = model.get_forecast(steps=steps).conf_int()
                    
                elif model_name == 'exponential_smoothing':
                    forecast = model.forecast(steps=steps)
                    # ä¿¡é ¼åŒºé–“ã®ç°¡æ˜“è¨ˆç®—
                    residuals_std = np.std(model.resid)
                    conf_int = pd.DataFrame({
                        'lower': forecast - 1.96 * residuals_std,
                        'upper': forecast + 1.96 * residuals_std
                    })
                
                forecasts[model_name] = {
                    'forecast': forecast,
                    'conf_int': conf_int,
                    'model_type': model_name
                }
                
                print(f"{model_name} äºˆæ¸¬å®Œäº†: {steps}æ—¥åˆ†")
                
            except Exception as e:
                print(f"{model_name} äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
        
        self.forecast_results = forecasts
        return forecasts
    
    def evaluate_models(self, ts_data, test_size=30):
        """ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®è©•ä¾¡"""
        if len(ts_data) < test_size * 2:
            print("è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return {}
        
        # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        train_data = ts_data[:-test_size]
        test_data = ts_data[-test_size:]
        
        evaluation_results = {}
        
        # å„ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ãƒ»è©•ä¾¡
        for model_name in self.models.keys():
            try:
                if model_name == 'arima':
                    # ARIMA ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
                    arima_model = ARIMA(train_data, order=self.models[model_name]['params'])
                    fitted_model = arima_model.fit()
                    forecast = fitted_model.forecast(steps=test_size)
                    
                elif model_name == 'exponential_smoothing':
                    # æŒ‡æ•°å¹³æ»‘æ³•ã§äºˆæ¸¬
                    if self.models[model_name]['type'] == 'simple':
                        es_model = ExponentialSmoothing(train_data, trend=None, seasonal=None)
                    elif self.models[model_name]['type'] == 'holt':
                        es_model = ExponentialSmoothing(train_data, trend='add', seasonal=None)
                    else:  # holt_winters
                        es_model = ExponentialSmoothing(
                            train_data, trend='add', seasonal='add', seasonal_periods=7
                        )
                    
                    fitted_model = es_model.fit()
                    forecast = fitted_model.forecast(steps=test_size)
                
                # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
                mae = mean_absolute_error(test_data, forecast)
                rmse = np.sqrt(mean_squared_error(test_data, forecast))
                mape = np.mean(np.abs((test_data - forecast) / test_data)) * 100
                
                evaluation_results[model_name] = {
                    'MAE': mae,
                    'RMSE': rmse,
                    'MAPE': mape,
                    'forecast': forecast,
                    'actual': test_data
                }
                
                print(f"{model_name} è©•ä¾¡å®Œäº† - MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.2f}%")
                
            except Exception as e:
                print(f"{model_name} è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
        
        return evaluation_results
    
    def visualize_forecasts(self, ts_data, evaluation_results=None):
        """äºˆæ¸¬çµæœã®å¯è¦–åŒ–"""
        fig, axes = plt.subplots(2, 2, figsize=(18, 12))
        
        # 1. å…¨ä½“ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿
        ax1 = axes[0, 0]
        ts_data.plot(ax=ax1, label='å®Ÿç¸¾å€¤', color='blue', alpha=0.7)
        
        # äºˆæ¸¬çµæœã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        if self.forecast_results:
            start_date = ts_data.index[-1]
            
            for model_name, forecast_data in self.forecast_results.items():
                forecast = forecast_data['forecast']
                future_dates = pd.date_range(
                    start=start_date + pd.Timedelta(days=1), 
                    periods=len(forecast), 
                    freq='D'
                )
                
                color = {'arima': 'red', 'exponential_smoothing': 'green'}.get(model_name, 'orange')
                
                ax1.plot(future_dates, forecast, label=f'{model_name} äºˆæ¸¬', 
                        color=color, linestyle='--', linewidth=2)
                
                # ä¿¡é ¼åŒºé–“
                conf_int = forecast_data['conf_int']
                ax1.fill_between(future_dates, conf_int.iloc[:, 0], conf_int.iloc[:, 1], 
                               color=color, alpha=0.2)
        
        ax1.set_title('æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¨äºˆæ¸¬çµæœ')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³
        ax2 = axes[0, 1]
        if len(ts_data) > 14:
            # æ›œæ—¥åˆ¥ã®å¹³å‡éœ€è¦
            ts_df = ts_data.to_frame('quantity')
            ts_df['weekday'] = ts_df.index.dayofweek
            weekday_avg = ts_df.groupby('weekday')['quantity'].mean()
            
            weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
            ax2.bar(weekday_names, weekday_avg.values, color='lightcoral', alpha=0.7)
            ax2.set_title('æ›œæ—¥åˆ¥å¹³å‡éœ€è¦')
            ax2.set_ylabel('å¹³å‡éœ€è¦')
        
        # 3. ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼ˆè©•ä¾¡çµæœãŒã‚ã‚‹å ´åˆï¼‰
        ax3 = axes[1, 0]
        if evaluation_results:
            models = list(evaluation_results.keys())
            mae_scores = [evaluation_results[m]['MAE'] for m in models]
            mape_scores = [evaluation_results[m]['MAPE'] for m in models]
            
            x = range(len(models))
            width = 0.35
            
            ax3_twin = ax3.twinx()
            
            bars1 = ax3.bar([i - width/2 for i in x], mae_scores, width, 
                           label='MAE', color='skyblue', alpha=0.7)
            bars2 = ax3_twin.bar([i + width/2 for i in x], mape_scores, width, 
                                label='MAPE (%)', color='lightgreen', alpha=0.7)
            
            ax3.set_xlabel('ãƒ¢ãƒ‡ãƒ«')
            ax3.set_ylabel('MAE')
            ax3_twin.set_ylabel('MAPE (%)')
            ax3.set_title('ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ')
            ax3.set_xticks(x)
            ax3.set_xticklabels(models)
            
            # æ•°å€¤ãƒ©ãƒ™ãƒ«è¿½åŠ 
            for bar, value in zip(bars1, mae_scores):
                ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                        f'{value:.1f}', ha='center', va='bottom')
            
            for bar, value in zip(bars2, mape_scores):
                ax3_twin.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                             f'{value:.1f}%', ha='center', va='bottom')
        
        # 4. æ®‹å·®åˆ†æ
        ax4 = axes[1, 1]
        if evaluation_results:
            for model_name, results in evaluation_results.items():
                residuals = results['actual'] - results['forecast']
                ax4.hist(residuals, bins=15, alpha=0.5, label=f'{model_name} æ®‹å·®')
            
            ax4.set_title('äºˆæ¸¬æ®‹å·®åˆ†å¸ƒ')
            ax4.set_xlabel('æ®‹å·®')
            ax4.set_ylabel('é »åº¦')
            ax4.legend()
            ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜
        output_dir = Path("results/forecasting")
        output_dir.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_dir / "forecast_analysis.png", dpi=300, bbox_inches='tight')
        
        return fig
    
    def save_forecast_results(self):
        """äºˆæ¸¬çµæœã®ä¿å­˜"""
        if not self.forecast_results:
            print("ä¿å­˜ã™ã‚‹äºˆæ¸¬çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        output_dir = Path("results/forecasting")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœã‚’ä¿å­˜
        for model_name, forecast_data in self.forecast_results.items():
            forecast_df = pd.DataFrame({
                'forecast': forecast_data['forecast'],
                'lower_bound': forecast_data['conf_int'].iloc[:, 0],
                'upper_bound': forecast_data['conf_int'].iloc[:, 1]
            })
            
            # æ—¥ä»˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
            start_date = pd.Timestamp.now().date()
            forecast_df['date'] = pd.date_range(
                start=start_date, 
                periods=len(forecast_df), 
                freq='D'
            )
            
            # ä¿å­˜
            filename = output_dir / f"{model_name}_forecast.csv"
            forecast_df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"{model_name} äºˆæ¸¬çµæœã‚’ä¿å­˜: {filename}")
        
        return output_dir

def create_sample_time_series_data():
    """ã‚µãƒ³ãƒ—ãƒ«æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
    np.random.seed(42)
    
    # 1å¹´åˆ†ã®æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿
    dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')
    
    # ãƒ™ãƒ¼ã‚¹éœ€è¦
    base_demand = 50
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆå¹´é–“ã§20%å¢—åŠ ï¼‰
    trend = np.linspace(0, base_demand * 0.2, len(dates))
    
    # å­£ç¯€æ€§ï¼ˆé€±æ¬¡ãƒ»æœˆæ¬¡ï¼‰
    weekly_seasonality = 10 * np.sin(2 * np.pi * np.arange(len(dates)) / 7)
    monthly_seasonality = 5 * np.sin(2 * np.pi * np.arange(len(dates)) / 30)
    
    # ãƒã‚¤ã‚º
    noise = np.random.normal(0, 5, len(dates))
    
    # æœ€çµ‚çš„ãªéœ€è¦ãƒ‡ãƒ¼ã‚¿
    demand = base_demand + trend + weekly_seasonality + monthly_seasonality + noise
    demand = np.maximum(demand, 0)  # è² ã®å€¤ã‚’0ã«ã‚¯ãƒªãƒƒãƒ—
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    ts_data = pd.DataFrame({
        'date': dates,
        'product_id': 'PROD_0001',
        'quantity': demand.astype(int)
    })
    
    # ä¿å­˜
    output_dir = Path("data/sample_data")
    output_dir.mkdir(parents=True, exist_ok=True)
    ts_data.to_csv(output_dir / "time_series_demand.csv", index=False, encoding='utf-8-sig')
    print(f"ã‚µãƒ³ãƒ—ãƒ«æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ: {output_dir / 'time_series_demand.csv'}")
    
    return ts_data

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("æ™‚ç³»åˆ—éœ€è¦äºˆæ¸¬ã‚’é–‹å§‹ã—ã¾ã™...")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    if not Path("data/sample_data/time_series_demand.csv").exists():
        print("ã‚µãƒ³ãƒ—ãƒ«æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
        create_sample_time_series_data()
    
    # äºˆæ¸¬å™¨ã®åˆæœŸåŒ–
    forecaster = TimeSeriesForecaster()
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    ts_data = forecaster.load_and_prepare_data(
        "data/sample_data/time_series_demand.csv", 
        "PROD_0001"
    )
    
    if ts_data is None:
        return
    
    # å­£ç¯€åˆ†è§£
    decomposition = forecaster.seasonal_decomposition(ts_data)
    
    # å®šå¸¸æ€§ãƒã‚§ãƒƒã‚¯
    is_stationary = forecaster.check_stationarity(ts_data)
    
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    print("\nARIMAãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
    arima_model = forecaster.fit_arima_model(ts_data)
    
    print("\næŒ‡æ•°å¹³æ»‘æ³•ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
    es_model = forecaster.fit_exponential_smoothing(ts_data)
    
    # äºˆæ¸¬å®Ÿè¡Œ
    print("\näºˆæ¸¬ã‚’å®Ÿè¡Œä¸­...")
    forecasts = forecaster.generate_forecasts(steps=30)
    
    # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
    print("\nãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚’è©•ä¾¡ä¸­...")
    evaluation = forecaster.evaluate_models(ts_data)
    
    # å¯è¦–åŒ–
    forecaster.visualize_forecasts(ts_data, evaluation)
    
    # çµæœä¿å­˜
    forecaster.save_forecast_results()
    
    # æœ€é©ãƒ¢ãƒ‡ãƒ«ã®æ¨å¥¨
    if evaluation:
        best_model = min(evaluation.items(), key=lambda x: x[1]['MAPE'])
        print(f"\nğŸ† æ¨å¥¨ãƒ¢ãƒ‡ãƒ«: {best_model[0]} (MAPE: {best_model[1]['MAPE']:.2f}%)")
    
    print("\nâœ… æ™‚ç³»åˆ—éœ€è¦äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("ğŸ“Š results/forecasting/ ãƒ•ã‚©ãƒ«ãƒ€ã«çµæœãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚")

if __name__ == "__main__":
    main()
