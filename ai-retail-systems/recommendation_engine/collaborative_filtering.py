"""
å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã‚·ã‚¹ãƒ†ãƒ 
ãƒ¦ãƒ¼ã‚¶ãƒ¼é–“ãƒ»ã‚¢ã‚¤ãƒ†ãƒ é–“ã®é¡ä¼¼æ€§ã«åŸºã¥ãæ¨è–¦ã‚¨ãƒ³ã‚¸ãƒ³
"""

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import TruncatedSVD
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.sparse import csr_matrix
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class CollaborativeFilteringRecommender:
    def __init__(self):
        """å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        self.user_item_matrix = None
        self.user_similarity = None
        self.item_similarity = None
        self.svd_model = None
        self.user_means = None
        self.global_mean = None
        
    def load_interaction_data(self, file_path):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç›¸äº’ä½œç”¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            df = pd.read_csv(file_path)
            
            required_columns = ['user_id', 'product_id', 'rating']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                print(f"å¿…è¦ãªåˆ—ãŒä¸è¶³: {missing_columns}")
                return None
            
            # è©•ä¾¡å€¤ã®æ­£è¦åŒ–ï¼ˆ1-5ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
            if df['rating'].min() >= 0 and df['rating'].max() <= 1:
                df['rating'] = df['rating'] * 5  # 0-1 â†’ 0-5
            
            print(f"ç›¸äº’ä½œç”¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:")
            print(f"  ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {df['user_id'].nunique()}")
            print(f"  å•†å“æ•°: {df['product_id'].nunique()}")
            print(f"  è©•ä¾¡æ•°: {len(df)}")
            print(f"  ã‚¹ãƒ‘ãƒ¼ã‚¹ç‡: {1 - len(df) / (df['user_id'].nunique() * df['product_id'].nunique()):.3f}")
            
            return df
            
        except Exception as e:
            print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def create_user_item_matrix(self, df):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼-ã‚¢ã‚¤ãƒ†ãƒ è¡Œåˆ—ã®ä½œæˆ"""
        # ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        user_item_matrix = df.pivot_table(
            index='user_id', 
            columns='product_id', 
            values='rating', 
            fill_value=0
        )
        
        self.user_item_matrix = user_item_matrix
        self.global_mean = df['rating'].mean()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å¹³å‡è©•ä¾¡ã®è¨ˆç®—
        user_ratings = df.groupby('user_id')['rating'].mean()
        self.user_means = user_ratings.reindex(user_item_matrix.index, fill_value=self.global_mean)
        
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼-ã‚¢ã‚¤ãƒ†ãƒ è¡Œåˆ—ä½œæˆå®Œäº†: {user_item_matrix.shape}")
        
        return user_item_matrix
    
    def calculate_user_similarity(self, method='cosine'):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼é–“é¡ä¼¼åº¦ã®è¨ˆç®—"""
        if self.user_item_matrix is None:
            print("ãƒ¦ãƒ¼ã‚¶ãƒ¼-ã‚¢ã‚¤ãƒ†ãƒ è¡Œåˆ—ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        
        print("ãƒ¦ãƒ¼ã‚¶ãƒ¼é–“é¡ä¼¼åº¦ã‚’è¨ˆç®—ä¸­...")
        
        if method == 'cosine':
            # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
            # 0è©•ä¾¡ã‚’é™¤å¤–ã™ã‚‹ãŸã‚ã€éã‚¼ãƒ­è¦ç´ ã®ã¿ã§è¨ˆç®—
            matrix_nonzero = self.user_item_matrix.copy()
            matrix_nonzero[matrix_nonzero == 0] = np.nan
            
            user_similarity = np.zeros((len(self.user_item_matrix), len(self.user_item_matrix)))
            
            for i in range(len(self.user_item_matrix)):
                for j in range(i, len(self.user_item_matrix)):
                    user_i = matrix_nonzero.iloc[i].dropna()
                    user_j = matrix_nonzero.iloc[j].dropna()
                    
                    # å…±é€šè©•ä¾¡ã‚¢ã‚¤ãƒ†ãƒ 
                    common_items = user_i.index.intersection(user_j.index)
                    
                    if len(common_items) > 0:
                        ratings_i = user_i.loc[common_items]
                        ratings_j = user_j.loc[common_items]
                        
                        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
                        dot_product = np.dot(ratings_i, ratings_j)
                        norm_i = np.linalg.norm(ratings_i)
                        norm_j = np.linalg.norm(ratings_j)
                        
                        if norm_i > 0 and norm_j > 0:
                            similarity = dot_product / (norm_i * norm_j)
                        else:
                            similarity = 0
                    else:
                        similarity = 0
                    
                    user_similarity[i, j] = similarity
                    user_similarity[j, i] = similarity
        
        self.user_similarity = pd.DataFrame(
            user_similarity,
            index=self.user_item_matrix.index,
            columns=self.user_item_matrix.index
        )
        
        print("ãƒ¦ãƒ¼ã‚¶ãƒ¼é–“é¡ä¼¼åº¦è¨ˆç®—å®Œäº†")
        
        return self.user_similarity
    
    def calculate_item_similarity(self, method='cosine'):
        """ã‚¢ã‚¤ãƒ†ãƒ é–“é¡ä¼¼åº¦ã®è¨ˆç®—"""
        if self.user_item_matrix is None:
            print("ãƒ¦ãƒ¼ã‚¶ãƒ¼-ã‚¢ã‚¤ãƒ†ãƒ è¡Œåˆ—ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        
        print("ã‚¢ã‚¤ãƒ†ãƒ é–“é¡ä¼¼åº¦ã‚’è¨ˆç®—ä¸­...")
        
        # ã‚¢ã‚¤ãƒ†ãƒ Ã—ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œåˆ—ï¼ˆè»¢ç½®ï¼‰
        item_user_matrix = self.user_item_matrix.T
        
        if method == 'cosine':
            # éã‚¼ãƒ­è¦ç´ ã®ã¿ã§é¡ä¼¼åº¦è¨ˆç®—
            matrix_nonzero = item_user_matrix.copy()
            matrix_nonzero[matrix_nonzero == 0] = np.nan
            
            item_similarity = np.zeros((len(item_user_matrix), len(item_user_matrix)))
            
            for i in range(len(item_user_matrix)):
                for j in range(i, len(item_user_matrix)):
                    item_i = matrix_nonzero.iloc[i].dropna()
                    item_j = matrix_nonzero.iloc[j].dropna()
                    
                    # å…±é€šè©•ä¾¡ãƒ¦ãƒ¼ã‚¶ãƒ¼
                    common_users = item_i.index.intersection(item_j.index)
                    
                    if len(common_users) > 0:
                        ratings_i = item_i.loc[common_users]
                        ratings_j = item_j.loc[common_users]
                        
                        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
                        dot_product = np.dot(ratings_i, ratings_j)
                        norm_i = np.linalg.norm(ratings_i)
                        norm_j = np.linalg.norm(ratings_j)
                        
                        if norm_i > 0 and norm_j > 0:
                            similarity = dot_product / (norm_i * norm_j)
                        else:
                            similarity = 0
                    else:
                        similarity = 0
                    
                    item_similarity[i, j] = similarity
                    item_similarity[j, i] = similarity
        
        self.item_similarity = pd.DataFrame(
            item_similarity,
            index=item_user_matrix.index,
            columns=item_user_matrix.index
        )
        
        print("ã‚¢ã‚¤ãƒ†ãƒ é–“é¡ä¼¼åº¦è¨ˆç®—å®Œäº†")
        
        return self.item_similarity
    
    def matrix_factorization(self, n_components=50):
        """è¡Œåˆ—åˆ†è§£ã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›"""
        if self.user_item_matrix is None:
            print("ãƒ¦ãƒ¼ã‚¶ãƒ¼-ã‚¢ã‚¤ãƒ†ãƒ è¡Œåˆ—ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        
        print(f"è¡Œåˆ—åˆ†è§£ã‚’å®Ÿè¡Œä¸­ï¼ˆæˆåˆ†æ•°: {n_components}ï¼‰...")
        
        # SVDï¼ˆç‰¹ç•°å€¤åˆ†è§£ï¼‰
        self.svd_model = TruncatedSVD(n_components=n_components, random_state=42)
        
        # è¡Œåˆ—åˆ†è§£å®Ÿè¡Œ
        user_factors = self.svd_model.fit_transform(self.user_item_matrix)
        item_factors = self.svd_model.components_
        
        print(f"è¡Œåˆ—åˆ†è§£å®Œäº†")
        print(f"  èª¬æ˜å¯èƒ½åˆ†æ•£æ¯”: {self.svd_model.explained_variance_ratio_.sum():.3f}")
        
        return user_factors, item_factors
    
    def predict_user_based(self, user_id, product_id, k=10):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ™ãƒ¼ã‚¹å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°äºˆæ¸¬"""
        if self.user_similarity is None:
            print("ãƒ¦ãƒ¼ã‚¶ãƒ¼é¡ä¼¼åº¦ãŒè¨ˆç®—ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return self.global_mean
        
        if user_id not in self.user_item_matrix.index:
            return self.global_mean
        
        if product_id not in self.user_item_matrix.columns:
            return self.global_mean
        
        # å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å–å¾—
        user_similarities = self.user_similarity.loc[user_id].sort_values(ascending=False)
        
        # å¯¾è±¡å•†å“ã‚’è©•ä¾¡æ¸ˆã¿ã®é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼
        similar_users = []
        for similar_user_id, similarity in user_similarities.items():
            if similar_user_id != user_id and similarity > 0:
                if self.user_item_matrix.loc[similar_user_id, product_id] > 0:
                    similar_users.append((similar_user_id, similarity))
                
                if len(similar_users) >= k:
                    break
        
        if len(similar_users) == 0:
            return self.user_means.loc[user_id]
        
        # äºˆæ¸¬è©•ä¾¡å€¤è¨ˆç®—
        numerator = 0
        denominator = 0
        
        user_mean = self.user_means.loc[user_id]
        
        for similar_user_id, similarity in similar_users:
            similar_user_rating = self.user_item_matrix.loc[similar_user_id, product_id]
            similar_user_mean = self.user_means.loc[similar_user_id]
            
            numerator += similarity * (similar_user_rating - similar_user_mean)
            denominator += abs(similarity)
        
        if denominator > 0:
            predicted_rating = user_mean + numerator / denominator
        else:
            predicted_rating = user_mean
        
        # è©•ä¾¡å€¤ã‚’1-5ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
        return np.clip(predicted_rating, 1, 5)
    
    def predict_item_based(self, user_id, product_id, k=10):
        """ã‚¢ã‚¤ãƒ†ãƒ ãƒ™ãƒ¼ã‚¹å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°äºˆæ¸¬"""
        if self.item_similarity is None:
            print("ã‚¢ã‚¤ãƒ†ãƒ é¡ä¼¼åº¦ãŒè¨ˆç®—ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return self.global_mean
        
        if user_id not in self.user_item_matrix.index:
            return self.global_mean
        
        if product_id not in self.user_item_matrix.columns:
            return self.global_mean
        
        # å¯¾è±¡å•†å“ã®é¡ä¼¼å•†å“ã‚’å–å¾—
        item_similarities = self.item_similarity.loc[product_id].sort_values(ascending=False)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©•ä¾¡æ¸ˆã¿ã®é¡ä¼¼å•†å“
        similar_items = []
        for similar_item_id, similarity in item_similarities.items():
            if similar_item_id != product_id and similarity > 0:
                if self.user_item_matrix.loc[user_id, similar_item_id] > 0:
                    similar_items.append((similar_item_id, similarity))
                
                if len(similar_items) >= k:
                    break
        
        if len(similar_items) == 0:
            return self.global_mean
        
        # äºˆæ¸¬è©•ä¾¡å€¤è¨ˆç®—
        numerator = 0
        denominator = 0
        
        for similar_item_id, similarity in similar_items:
            user_rating = self.user_item_matrix.loc[user_id, similar_item_id]
            
            numerator += similarity * user_rating
            denominator += abs(similarity)
        
        if denominator > 0:
            predicted_rating = numerator / denominator
        else:
            predicted_rating = self.global_mean
        
        # è©•ä¾¡å€¤ã‚’1-5ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
        return np.clip(predicted_rating, 1, 5)
    
    def predict_matrix_factorization(self, user_id, product_id):
        """è¡Œåˆ—åˆ†è§£ã«ã‚ˆã‚‹äºˆæ¸¬"""
        if self.svd_model is None:
            print("è¡Œåˆ—åˆ†è§£ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return self.global_mean
        
        if user_id not in self.user_item_matrix.index:
            return self.global_mean
        
        if product_id not in self.user_item_matrix.columns:
            return self.global_mean
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        user_idx = self.user_item_matrix.index.get_loc(user_id)
        item_idx = self.user_item_matrix.columns.get_loc(product_id)
        
        # SVDãƒ¢ãƒ‡ãƒ«ã‹ã‚‰äºˆæ¸¬
        user_factors = self.svd_model.transform(self.user_item_matrix)
        item_factors = self.svd_model.components_
        
        predicted_rating = np.dot(user_factors[user_idx], item_factors[:, item_idx])
        
        # è©•ä¾¡å€¤ã‚’1-5ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
        return np.clip(predicted_rating, 1, 5)
    
    def recommend_items(self, user_id, n_recommendations=10, method='item_based'):
        """ã‚¢ã‚¤ãƒ†ãƒ æ¨è–¦"""
        if user_id not in self.user_item_matrix.index:
            print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ {user_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœªè©•ä¾¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’å–å¾—
        user_ratings = self.user_item_matrix.loc[user_id]
        unrated_items = user_ratings[user_ratings == 0].index.tolist()
        
        if len(unrated_items) == 0:
            print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ {user_id} ã®æœªè©•ä¾¡ã‚¢ã‚¤ãƒ†ãƒ ãŒã‚ã‚Šã¾ã›ã‚“")
            return []
        
        # å„æœªè©•ä¾¡ã‚¢ã‚¤ãƒ†ãƒ ã®äºˆæ¸¬è©•ä¾¡å€¤ã‚’è¨ˆç®—
        predictions = []
        
        for item_id in unrated_items:
            if method == 'user_based':
                predicted_rating = self.predict_user_based(user_id, item_id)
            elif method == 'item_based':
                predicted_rating = self.predict_item_based(user_id, item_id)
            elif method == 'matrix_factorization':
                predicted_rating = self.predict_matrix_factorization(user_id, item_id)
            else:
                predicted_rating = self.global_mean
            
            predictions.append((item_id, predicted_rating))
        
        # äºˆæ¸¬è©•ä¾¡å€¤ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½Nå€‹ã‚’è¿”ã™
        predictions.sort(key=lambda x: x[1], reverse=True)
        
        return predictions[:n_recommendations]
    
    def evaluate_model(self, df, test_size=0.2, methods=['user_based', 'item_based', 'matrix_factorization']):
        """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡"""
        print("ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã‚’å®Ÿè¡Œä¸­...")
        
        # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        train_df, test_df = train_test_split(df, test_size=test_size, random_state=42)
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
        train_matrix = self.create_user_item_matrix(train_df)
        
        if 'user_based' in methods:
            self.calculate_user_similarity()
        if 'item_based' in methods:
            self.calculate_item_similarity()
        if 'matrix_factorization' in methods:
            self.matrix_factorization()
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ãƒ»è©•ä¾¡
        evaluation_results = {}
        
        for method in methods:
            predictions = []
            actuals = []
            
            for _, row in test_df.iterrows():
                user_id = row['user_id']
                product_id = row['product_id']
                actual_rating = row['rating']
                
                if method == 'user_based':
                    predicted_rating = self.predict_user_based(user_id, product_id)
                elif method == 'item_based':
                    predicted_rating = self.predict_item_based(user_id, product_id)
                elif method == 'matrix_factorization':
                    predicted_rating = self.predict_matrix_factorization(user_id, product_id)
                
                predictions.append(predicted_rating)
                actuals.append(actual_rating)
            
            # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
            mse = mean_squared_error(actuals, predictions)
            rmse = np.sqrt(mse)
            mae = np.mean(np.abs(np.array(actuals) - np.array(predictions)))
            
            evaluation_results[method] = {
                'RMSE': rmse,
                'MAE': mae,
                'MSE': mse
            }
            
            print(f"{method} - RMSE: {rmse:.3f}, MAE: {mae:.3f}")
        
        return evaluation_results
    
    def visualize_recommendations(self):
        """æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®å¯è¦–åŒ–"""
        if self.user_item_matrix is None:
            print("å¯è¦–åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼-ã‚¢ã‚¤ãƒ†ãƒ è¡Œåˆ—ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
        ax1 = axes[0, 0]
        sample_matrix = self.user_item_matrix.iloc[:20, :20]  # 20x20ã®ã‚µãƒ³ãƒ—ãƒ«
        sns.heatmap(sample_matrix, ax=ax1, cmap='YlOrRd', cbar_kws={'label': 'Rating'})
        ax1.set_title('User-Item Matrix (Sample)')
        ax1.set_xlabel('Products')
        ax1.set_ylabel('Users')
        
        # 2. è©•ä¾¡å€¤åˆ†å¸ƒ
        ax2 = axes[0, 1]
        ratings = self.user_item_matrix.values.flatten()
        ratings_nonzero = ratings[ratings > 0]
        ax2.hist(ratings_nonzero, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax2.set_title('Rating Distribution')
        ax2.set_xlabel('Rating')
        ax2.set_ylabel('Count')
        ax2.grid(True, alpha=0.3)
        
        # 3. ãƒ¦ãƒ¼ã‚¶ãƒ¼é¡ä¼¼åº¦åˆ†å¸ƒï¼ˆä¸Šä½é¡ä¼¼åº¦ã®ã¿ï¼‰
        if self.user_similarity is not None:
            ax3 = axes[1, 0]
            # å¯¾è§’è¦ç´ ï¼ˆè‡ªåˆ†è‡ªèº«ï¼‰ã‚’é™¤ã„ãŸé¡ä¼¼åº¦
            similarity_values = []
            for i in range(len(self.user_similarity)):
                for j in range(i+1, len(self.user_similarity)):
                    similarity_values.append(self.user_similarity.iloc[i, j])
            
            similarity_values = [s for s in similarity_values if s > 0]  # æ­£ã®é¡ä¼¼åº¦ã®ã¿
            
            if len(similarity_values) > 0:
                ax3.hist(similarity_values, bins=30, alpha=0.7, color='lightgreen')
                ax3.set_title('User Similarity Distribution')
                ax3.set_xlabel('Cosine Similarity')
                ax3.set_ylabel('Count')
                ax3.grid(True, alpha=0.3)
        
        # 4. ã‚¢ã‚¤ãƒ†ãƒ é¡ä¼¼åº¦åˆ†å¸ƒ
        if self.item_similarity is not None:
            ax4 = axes[1, 1]
            # å¯¾è§’è¦ç´ ã‚’é™¤ã„ãŸé¡ä¼¼åº¦
            similarity_values = []
            for i in range(len(self.item_similarity)):
                for j in range(i+1, len(self.item_similarity)):
                    similarity_values.append(self.item_similarity.iloc[i, j])
            
            similarity_values = [s for s in similarity_values if s > 0]  # æ­£ã®é¡ä¼¼åº¦ã®ã¿
            
            if len(similarity_values) > 0:
                ax4.hist(similarity_values, bins=30, alpha=0.7, color='lightcoral')
                ax4.set_title('Item Similarity Distribution')
                ax4.set_xlabel('Cosine Similarity')
                ax4.set_ylabel('Count')
                ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜
        output_dir = Path("results/recommendation")
        output_dir.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_dir / "collaborative_filtering_analysis.png", dpi=300, bbox_inches='tight')
        
        return fig
    
    def save_recommendations(self, user_recommendations, filename="recommendations.csv"):
        """æ¨è–¦çµæœã®ä¿å­˜"""
        output_dir = Path("results/recommendation")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ¨è–¦çµæœã‚’DataFrameã«å¤‰æ›
        recommendation_data = []
        
        for user_id, recommendations in user_recommendations.items():
            for rank, (item_id, predicted_rating) in enumerate(recommendations, 1):
                recommendation_data.append({
                    'user_id': user_id,
                    'product_id': item_id,
                    'predicted_rating': predicted_rating,
                    'recommendation_rank': rank
                })
        
        recommendations_df = pd.DataFrame(recommendation_data)
        
        # ä¿å­˜
        output_file = output_dir / filename
        recommendations_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"æ¨è–¦çµæœã‚’ä¿å­˜: {output_file}")
        
        return output_file

def create_sample_interaction_data():
    """ã‚µãƒ³ãƒ—ãƒ«ç›¸äº’ä½œç”¨ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
    np.random.seed(42)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨å•†å“ã®æ•°
    n_users = 200
    n_products = 100
    n_interactions = 5000
    
    users = [f"USER_{i:04d}" for i in range(1, n_users + 1)]
    products = [f"PROD_{i:04d}" for i in range(1, n_products + 1)]
    
    interaction_data = []
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆ
    user_preferences = {}
    for user in users:
        # å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ç‰¹å®šã®å•†å“ã‚«ãƒ†ã‚´ãƒªã‚’å¥½ã‚€å‚¾å‘
        preferred_categories = np.random.choice(5, size=np.random.randint(1, 4), replace=False)
        user_preferences[user] = preferred_categories
    
    # å•†å“ã®ã‚«ãƒ†ã‚´ãƒªã‚’è¨­å®š
    product_categories = {}
    for product in products:
        product_categories[product] = np.random.randint(0, 5)
    
    # ç›¸äº’ä½œç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    for _ in range(n_interactions):
        user = np.random.choice(users)
        product = np.random.choice(products)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ã«åŸºã¥ã„ã¦è©•ä¾¡å€¤ã‚’èª¿æ•´
        if product_categories[product] in user_preferences[user]:
            # å¥½ã¿ã®ã‚«ãƒ†ã‚´ãƒªã¯é«˜è©•ä¾¡å‚¾å‘
            rating = np.random.choice([3, 4, 5], p=[0.2, 0.4, 0.4])
        else:
            # å¥½ã¿ã§ãªã„ã‚«ãƒ†ã‚´ãƒªã¯ä½è©•ä¾¡å‚¾å‘
            rating = np.random.choice([1, 2, 3, 4, 5], p=[0.2, 0.3, 0.3, 0.15, 0.05])
        
        interaction_data.append({
            'user_id': user,
            'product_id': product,
            'rating': rating,
            'timestamp': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(0, 365))
        })
    
    # é‡è¤‡ã‚’é™¤å»
    df = pd.DataFrame(interaction_data)
    df = df.drop_duplicates(subset=['user_id', 'product_id']).reset_index(drop=True)
    
    # ä¿å­˜
    output_dir = Path("data/sample_data")
    output_dir.mkdir(parents=True, exist_ok=True)
    df.to_csv(output_dir / "user_interactions.csv", index=False, encoding='utf-8-sig')
    print(f"ã‚µãƒ³ãƒ—ãƒ«ç›¸äº’ä½œç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ: {output_dir / 'user_interactions.csv'}")
    print(f"  æœ€çµ‚ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}ä»¶")
    
    return df

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã™...")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    if not Path("data/sample_data/user_interactions.csv").exists():
        print("ã‚µãƒ³ãƒ—ãƒ«ç›¸äº’ä½œç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
        create_sample_interaction_data()
    
    # æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    recommender = CollaborativeFilteringRecommender()
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = recommender.load_interaction_data("data/sample_data/user_interactions.csv")
    if df is None:
        return
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼-ã‚¢ã‚¤ãƒ†ãƒ è¡Œåˆ—ä½œæˆ
    user_item_matrix = recommender.create_user_item_matrix(df)
    
    # é¡ä¼¼åº¦è¨ˆç®—
    print("\nãƒ¦ãƒ¼ã‚¶ãƒ¼é–“é¡ä¼¼åº¦ã‚’è¨ˆç®—ä¸­...")
    recommender.calculate_user_similarity()
    
    print("ã‚¢ã‚¤ãƒ†ãƒ é–“é¡ä¼¼åº¦ã‚’è¨ˆç®—ä¸­...")
    recommender.calculate_item_similarity()
    
    print("è¡Œåˆ—åˆ†è§£ã‚’å®Ÿè¡Œä¸­...")
    recommender.matrix_factorization()
    
    # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
    print("\nãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã‚’å®Ÿè¡Œä¸­...")
    evaluation_results = recommender.evaluate_model(df)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã™ã‚‹æ¨è–¦
    sample_users = df['user_id'].unique()[:5]
    user_recommendations = {}
    
    print("\nã‚µãƒ³ãƒ—ãƒ«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æ¨è–¦ã‚’å®Ÿè¡Œä¸­...")
    for user_id in sample_users:
        recommendations = recommender.recommend_items(user_id, n_recommendations=10, method='item_based')
        user_recommendations[user_id] = recommendations
        
        print(f"\nãƒ¦ãƒ¼ã‚¶ãƒ¼ {user_id} ã¸ã®æ¨è–¦:")
        for i, (product_id, rating) in enumerate(recommendations[:5], 1):
            print(f"  {i}. {product_id} (äºˆæ¸¬è©•ä¾¡: {rating:.2f})")
    
    # å¯è¦–åŒ–
    recommender.visualize_recommendations()
    
    # çµæœä¿å­˜
    recommender.save_recommendations(user_recommendations)
    
    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    print(f"\n=== å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ  ãƒ¬ãƒãƒ¼ãƒˆ ===")
    print(f"ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
    print(f"  ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {df['user_id'].nunique()}")
    print(f"  å•†å“æ•°: {df['product_id'].nunique()}")
    print(f"  è©•ä¾¡æ•°: {len(df)}")
    
    print(f"\nãƒ¢ãƒ‡ãƒ«æ€§èƒ½:")
    for method, metrics in evaluation_results.items():
        print(f"  {method}:")
        print(f"    RMSE: {metrics['RMSE']:.3f}")
        print(f"    MAE: {metrics['MAE']:.3f}")
    
    # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å®š
    best_method = min(evaluation_results.keys(), key=lambda x: evaluation_results[x]['RMSE'])
    print(f"\nğŸ† æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_method} (RMSE: {evaluation_results[best_method]['RMSE']:.3f})")
    
    print(f"\nâœ… å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("ğŸ“Š results/recommendation/ ãƒ•ã‚©ãƒ«ãƒ€ã«çµæœãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚")

if __name__ == "__main__":
    main()
